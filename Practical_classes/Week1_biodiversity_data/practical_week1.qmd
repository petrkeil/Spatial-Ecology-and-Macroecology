---
title: 'Spatial Ecology and Macroecology'
subtitle: 'Practical - Week 1'
date: 2024-09-30
author:
  - name: 'Florencia Grattarola'
    id: fg
    orcid: 0000-0001-8282-5732
    email: grattarola@fzp.czu.cz
    affiliation: 
      - name: MOBI Lab
        url: https://petrkeil.github.io/
format: 
  revealjs:
    self-contained: true
    logo: 'img/Logo_czu_cz_hr.png'
    auto-stretch: false
    code-copy: true
    code-tools: true
    enter-title-slide: false
    theme: [assets/monash.scss]
    controls: true
    width: 1280
    height: 720
    css: [assets/syntax-highlight.css, assets/custom.css, assets/pacman.css]
    highlight-style: github
    echo: true
    footer: '[https://github.com/petrkeil/Spatial-Ecology-and-Macroecology](https://github.com/petrkeil/Spatial-Ecology-and-Macroecology)'
editor: source
---

## What are we going to see today?

::: incremental
1.  Data types
2.  Data sources
3.  Open data
4.  Exercise 1: explore data sources
5.  Exercise 2: data download and cleaning in R (quality check)
:::

# Data types {background-color="#488fb8"}

## 1. Data types

Data that can place a particular **taxa** in a particular **location** and **time** can take many forms, depending on:

::: incremental
1.  What they record (*currency of the species' distribution*)
2.  How they are collected (*method*)
3.  How they are made available for others (*openness*)
:::


------------------------------------------------------------------------

## 1. Data types

**Presence-only (PO) data**

::: columns
::: {.column width="60%"}
-   For example: records from museum and herbarium collections or citizen-science initiatives
-   Characteristics: usually opportunistic, single species, spatio-temporally specific, absences are unknown 
:::

::: {.column width="40%"}
![](img/occurrence-records.png){fig-align="center" width="250"}
:::
:::

::: {.fragment}
| **PROS**                                              | **CONS**                                                                   |
|------------------------------------|------------------------------------|
| huge amounts of data available, easily aggregated | often without details of effort/method, wide variation in data quality |
:::

------------------------------------------------------------------------

## 1. Data types

**Presence-absence (PA) data**

::: columns
::: {.column width="60%"}
-   For example: data from inventories, checklists, atlas, acoustic sensors, DNA sampling or camera-trap surveys
-   Characteristics: multiple species, spatio-temporally specific, report searches that did not find the species (absences)
:::

::: {.column width="40%"}
![](img/sampling-events.png){fig-align="center" width="250"}
:::
:::

::: {.fragment}
| **PROS**                                                   | **CONS**                                                             |
|------------------------------------|------------------------------------|
| absences are informative, area and effort are measured | less abundant (too time consuming), methods are species-specific |
:::

------------------------------------------------------------------------

## 1. Data types

**Repeated surveys**

::: columns
::: {.column width="60%"}
-   For example: monitoring schemes, repeated atlas projects
-   Characteristics: multiple species, over time, spatially defined, use a standardized protocol
:::

::: {.column width="40%"}
![](img/atlas_2.png){fig-align="center" width="250"}
:::
:::

::: {.fragment}
| **PROS**                                             | **CONS**                                                         |
|------------------------------------|------------------------------------|
| standardised protocols, multiple points in time | expensive: geographically restricted, usually temporally too |
:::

------------------------------------------------------------------------

## 1. Data types

**Range-maps**

::: columns
::: {.column width="60%"}
-   outlines of species distributions, IUCN ranges, field guides
-   single species, expert-drawn
:::

::: {.column width="40%"}
![](img/range-map.png){fig-align="center" width="250"}
:::
:::

::: {.fragment}
| **PROS**                                                                                      | **CONS**                                     |
|------------------------------------|------------------------------------|
| rough estimates of the outer boundaries of areas within which species are likely to occur | large spatial and temporal uncertainties |
:::

------------------------------------------------------------------------

## 1. Data types

Data can also be defined as **how** they were collected.

------------------------------------------------------------------------

## 1. Data types

**Structured**

::: {layout-ncol="2"}
-   clear survey design (location, target) and standardised sampling protocol
-   site selection: preselected locations, sometimes stratified random
-   metadata: informs about the survey methods

![](img/structured.png)
:::

------------------------------------------------------------------------

## 1. Data types

**Semi-structured**

::: {layout-ncol="2"}
-   no survey design but *little* standardised sampling protocol\
-   site selection: free\
-   metadata: informs about the observation process and survey methods

![](img/semi-structured.png)
:::

------------------------------------------------------------------------

## 1. Data types

**Unstructured** (opportunistic)

::: {layout-ncol="2"}
-   no survey design and no standardised sampling protocol
-   site selection: free
-   metadata: almost non

![](img/unstructured.png)
:::

------------------------------------------------------------------------

## 1. Data types

Finally, data can also be defined as how they are **made available** for others.

------------------------------------------------------------------------

## 1. Data types

**Disaggregated**

::: {layout-ncol="3"}
-   precision is high, but completeness and representativeness are low.

![](img/occurrence-records.png)

![](img/sampling-events.png)
:::

------------------------------------------------------------------------

## 1. Data types

**Aggregated**  

::: {layout-ncol="3"}
-   precision is low, but completeness and representativeness are high.

![](img/range-map.png)

![](img/checklists.png)
:::

# 2. Data sources {background-color="#488fb8"}

------------------------------------------------------------------------

![](img/gbif-full-logo-green.png){.centre top="200" height="200"}

### [gbif.org](https://www.gbif.org)

**GBIF** is an international network and data infrastructure funded by the world's governments and aimed at providing anyone, anywhere, open access to data about all types of life on Earth.

![](https://github.com/ropensci/rgbif/raw/master/man/figures/logo.png){height="100"} `rgbif`: <https://github.com/ropensci/rgbif>

------------------------------------------------------------------------

![](img/obis-logo.png){.centre top="200" height="200"}

### [obis.org](https://obis.org)

**OBIS** is a global open-access data and information clearing-house on marine biodiversity for science, conservation and sustainable development.

![](https://github.com/iobis/robis/raw/master/man/figures/logo.png){height="100"} `robis`: <https://github.com/iobis/robis>

------------------------------------------------------------------------

![](img/logo-ebird-1200.png){.centre top="200" height="200"}

### [ebird.org](https://ebird.org/home)

**eBird**'s goal is to gather birdwatcher's knowledge and experience in the form of checklists of birds, archive it, and freely share it to power new data-driven approaches to science, conservation and education.

![](https://cornelllabofornithology.github.io/auk/logo.png){height="100"} `auk`: <https://cornelllabofornithology.github.io/auk/>

------------------------------------------------------------------------

![](img/logo-ebird-1200.png){.centre top="200" height="200"}

### [ebird.org](https://ebird.org/home)

**eBird**'s goal is to gather birdwatcher's knowledge and experience in the form of checklists of birds, archive it, and freely share it to power new data-driven approaches to science, conservation and education.

![](https://docs.ropensci.org/rebird/logo.png){height="100"} `rebird`: [https://github.com/ropensci/rebird](https://github.com/ropensci/rebird/)

------------------------------------------------------------------------

![](https://static.inaturalist.org/wiki_page_attachments/1419-original.png){.centre top="200" height="100"}

### [inaturalist.org](https://www.inaturalist.org)

**iNaturalist** is one of the world's most popular nature apps. It allows participants to contribute observations of any organism, or traces thereof, along with associated spatio-temporal metadata.

![](https://docs.ropensci.org/rebird/logo.png){height="100"} `rinat`: <https://github.com/ropensci/rinat>

------------------------------------------------------------------------

![](img/IUCN_Red_List.png){.centre top="200" height="200"}

### [iucnredlist.org](https://www.iucnredlist.org)

**IUCN**'s (International Union for Conservation of Nature) Red List of Threatened Species has evolved to become the world's most comprehensive information source on the global extinction risk status of animal, fungus and plant species.

![](https://docs.ropensci.org/rebird/logo.png){height="100"} `rredlist`: <https://github.com/ropensci/rredlist>

------------------------------------------------------------------------

![](img/IUCN_Red_List.png){.centre top="200" height="200"}

### [iucnredlist.org](https://www.iucnredlist.org)

**IUCN**'s (International Union for Conservation of Nature) Red List of Threatened Species has evolved to become the world's most comprehensive information source on the global extinction risk status of animal, fungus and plant species.

![](https://avatars.githubusercontent.com/u/29559340?s=200&v=4){height="100"} `redlistr`: <https://github.com/red-list-ecosystem/redlistr>

------------------------------------------------------------------------

![](https://mol.org/static/img/logo.png){.centre top="200" height="100"}

### [mol.org](https://mol.org)

**Map of Life** endeavors to provide 'best-possible' species range information and species lists for any geographic area. The Map of Life assembles and integrates different sources of data describing species distributions worldwide.

------------------------------------------------------------------------

![](https://ars.els-cdn.com/content/image/X23523409.jpg){.centre top="200" width="100"}

### [10.1016/j.dib.2017.05.007](https://doi.org/10.1016/j.dib.2017.05.007)

**Chorological maps for the main European woody species** is a data paper with a dataset of chorological maps for the main European tree and shrub species, put together by Giovanni Caudullo, Erik Welk, and Jesús San-Miguel-Ayanz.

------------------------------------------------------------------------

![](https://www.bto.org/sites/all/themes/egret/img/logo/bbs-logo-square.png){.centre top="200" height="200"}

### UK [bto.org/our-science/projects/breeding-bird-survey](https://www.bto.org/our-science/projects/breeding-bird-survey)
### USA [usgs.gov/centers/eesc/science/north-american-breeding-bird-survey](https://www.usgs.gov/centers/eesc/science/north-american-breeding-bird-survey)

**BBS** (Breeding Bird Survey) involves thousands of volunteer birdwatchers carrying out standardised annual bird counts on randomly-located 1-km sites. It's part of the NBN Atlas.

------------------------------------------------------------------------

![](https://bien.nceas.ucsb.edu/bien/wp-content/uploads/2021/01/FinalBIENLogoNoText_highres-768x303.png){.centre top="200" width="352"}

### [bien.nceas.ucsb.edu/bien/](https://bien.nceas.ucsb.edu/bien/)

**BIEN** is a network of ecologists, botanists, and computer scientists working together to document global patterns of plant diversity, function and distribution.

`rbien`: <https://github.com/bmaitner/RBIEN>

------------------------------------------------------------------------

![](https://sibbr.gov.br/img/logo.svg){.centre top="200" height="200"}

### [sibbr.gov.br](https://sibbr.gov.br/?lang=en_GB)

**SiBBr** (Brazilian Biodiversity Information System) is an online platform that integrates data and information about biodiversity and ecosystems from different sources, making them accessible for different uses.

![](https://avatars.githubusercontent.com/u/4728758?s=200&v=4){height="100"} **sibbr**: <https://github.com/sibbr>

------------------------------------------------------------------------

![](http://biotime.st-andrews.ac.uk/images/logo.png){.centre top="200" height="200"}

### [biotime.st-andrews.ac.uk](https://biotime.st-andrews.ac.uk)

BioTime is an open access database global database of assemblage time series for quantifying and understanding biodiversity change.

![](https://avatars.githubusercontent.com/u/29038235?s=200&v=4){width="80"} **BioTime Hub**: <https://github.com/bioTIMEHub>

# 3. Open Data {background-color="#488fb8"}

## 3. Open Data

**Open** means anyone can freely access, use, modify, and share for any purpose.

<br>

![](http://opendefinition.org/assets.okfn.org/images/ok_buttons/od_80x15_blue.png){.centre top="200" height="50"}

::: {.callout-important}
## Public doesn't mean open

The data on the internet can be public but they are not necessarily open. They can be standard, available in open formats (e.g., csv), and yet, if they don't have a licence, by default they are closed (all rights reserved).
:::

------------------------------------------------------------------------

## 3. Open Data: Data standards

**Darwin Core** is the internationally agreed data standard to facilitate the sharing of information about biological diversity.

### [dwc.tdwg.org](https://dwc.tdwg.org/terms/)


::: columns

::: {.column width="40%"}
![](img/tdwg-logo-home.png){.centre top="200" height="200"}
:::

::: {.column width="60%"}
::: {.fragment}
`countryCode`: The standard code for the country in which the Location occurs. Recommended best practice is to use an ISO 3166-1-alpha-2 country code.\ 
:::

::: {.fragment}
`recordedBy`: A list (concatenated and separated) of names of people, groups, or organizations responsible for recording the original Occurrence.
:::
:::

:::
------------------------------------------------------------------------

## 3. Open Data: Licensing

Open data are licensed under open licenses. Some examples:

. . .

::: columns
::: {.column width="50%"}
![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/cc-zero.png)\
[**CC0**: Public domain]{.font-small}

![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by.png)\
[**CC-BY**: Attribution]{.font-small}
:::

::: {.column width="50%"}
![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc.png)\
[**CC-BY-NC**: Attribution - Non Commercial]{.font-small}

![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png)\
[**CC-BY-SA**: Attribution - Share Alike]{.font-small}
:::
:::

------------------------------------------------------------------------

## 3. Open Data: Data sharing

Data that are **standardized** and have an **open licence** can be shared :)

![](img/data-sharing.png){.absolute bottom="50" left="100" width="544" height="418"}

# [EXERCISE 1]{.story} [Explore different data sources]{style="float:right;text-align:right;"} {background-color="#488fb8"}

## Imagine you want to start a project:

Chose a taxon, chose **one** data source and try to get distribution data.

Then answer the following 3 questions:

::: incremental
-   What kind of **data types** does the source provide?
-   Which kind of **taxa** are covered by the database generally?
-   How **accessible** is the data? Can anyone download it? Restrictions?
-   What was your **experience**? What **issues** did you encounter while getting the data?
:::

::: aside
Should take around **5 minutes** :)\
Afterwards we will discuss some of your examples. Please be prepared to share your experience.
:::

# [EXERCISE 2]{.story} [Mammal's of the Czech Republic]{style="float:right;text-align:right;"} {background-color="#488fb8"}

We will use the mammals of Czech Republic as an example dataset. We will access data through [**GBIF**](https://gbif.org) using tools available in R. 

## Some preparation before starting to code

::: incremental
-   Create a new project for all your practical sessions (with `code` and `data` folders inside).
-   Comment your code as much as possible, as if you were to explain it to others (that other could be you in 3 months!).
-   Keep your code short and easily readable in plain English.
:::

::: {.fragment}
[File]{.font-big} \> [New project]{.font-big} \> [New directory]{.font-big} or [Existing directory]{.font-big}
:::

::: incremental
-   Download the code for today's practical from: [practical_week1_exercise2_STUDENTS_FILE.qmd](https://github.com/petrkeil/Spatial-Ecology-and-Macroecology/blob/3713ec0823ba08d540f3aeea5f8d1a0acb56c71b/Practical_classes/Week1_biodiversity_data/practical_week1_exercise2_STUDENTS_FILE.qmd)
:::

------------------------------------------------------------------------

## 1 Install and load libraries

::: {.fragment}
We will always load packages into R using the package **`pacman`**. 

```{r}
#| eval: false
#| echo: true
install.packages('pacman')
```

```{r}
library(pacman) # load
packageVersion('pacman')
```
:::

<br>

::: {.fragment}
If you attempt to load a library that is not installed, `pacman` will try to install it automatically.
:::

------------------------------------------------------------------------

## 1 Install and load libraries

We will use **`tidyverse`** for the manipulation and transformation of data.

```{r}
pacman::p_load(tidyverse) # Data wrangling
packageVersion('tidyverse')
```

<br>

::: {.fragment}
We will be using many functions from this library of package, like `filter()`, `mutate()`, and later `read_csv()`.
:::

------------------------------------------------------------------------

## 1 Install and load libraries

We will use **`rgbif`** to download data from GBIF directly into R.

```{r}
pacman::p_load(rgbif) # the GBIF R package
packageVersion('rgbif')
```

------------------------------------------------------------------------

## 1 Install and load libraries

We will need to get a taxon ID (`taxonKey`) for the *Mammalia* class from the GBIF backbone. For that we will use another package called **`taxize`**.

```{r}
pacman::p_load(taxize)
packageVersion('taxize')
```

------------------------------------------------------------------------

## 1 Install and load libraries

We will use **`sf`** to work with spatial data.

```{r}
pacman::p_load(sf)
packageVersion('sf')
```

------------------------------------------------------------------------

## 1 Install and load libraries

We will use **`rnaturalearth`** to interact with [Natural Earth](https://www.naturalearthdata.com/) to get mapping data into R (e.g., countries' polygons).

```{r}
pacman::p_load(rnaturalearth)
packageVersion('rnaturalearth')
```

------------------------------------------------------------------------

## 2 Project variables

Create some variables that will be used later.

```{r}
#| echo: true
#| eval: true
taxa <- "Mammalia"
country_code <- "CZ" # Two letters ISO code for Czechia
proj_crs <- 4326 # EPSG code for WGS84
```

## 2 Project variables

Get a taxon ID for the *Mammalia* class.

```{r}
#| echo: true
#| eval: true
taxon_key <- get_gbifid_(taxa) %>%
  bind_rows() %>% # Transform the result of get_gbifid into a dataframe
  filter(matchtype == "EXACT" & status == "ACCEPTED") %>% # Filter the dataframe by the columns "matchtype" and "status"
  pull(usagekey) # Pull the contents of the column "usagekey"

taxon_key
```

## 2 Project variables

Basemap of CZ to use later for plotting or checking the dataset.

```{r}
#| warning: FALSE
#| message: FALSE
#| echo: TRUE

base_map <- rnaturalearth::ne_countries(
  scale = 110,
  type = 'countries',
  country = 'czechia',
  returnclass = 'sf'
)
```

------------------------------------------------------------------------

## 3 GBIF data download

And now we can use the function `occ_count()` to find out the **number of occurrence records** for the entire Czech Republic.

::: {.fragment}
``` r
occ_count(
  taxonKey = NULL,
  georeferenced = NULL,
  basisOfRecord = NULL,
  datasetKey = NULL,
  date = NULL,
  typeStatus = NULL,
  country = NULL,
  year = NULL,
  from = 2000,
  to = 2012,
  type = "count",
  publishingCountry = "US",
  protocol = NULL,
  curlopts = list()
)
```
:::

------------------------------------------------------------------------

## 3 GBIF data download

How many occurrence records are in GBIF for the entire **Czech Republic**?

::: {.fragment}
```{r}
#| echo: true
#| eval: true
occ_count(country=country_code) # country code for Czech Republic (https://countrycode.org/)
```
:::

<br> 

::: {.fragment}
And how many records for the **mammals** of Czech Republic?
:::

::: {.fragment}
```{r}
#| echo: true
#| eval: true
occ_count(
  country = country_code,
  taxonKey = taxon_key
)
```
:::

<br> 

::: {.fragment}
We are ready to do a download. [Whoop!]{.font-big}\
:::

------------------------------------------------------------------------

## 3.1 CZ mammals' GBIF data download

To do this, we will use `occ_search()`, **but see `occ_download()`**.

::: {.fragment}
``` r
occ_search(
  taxonKey = NULL,
  scientificName = NULL,
  country = NULL,
  publishingCountry = NULL,
  hasCoordinate = NULL,
  typeStatus = NULL,
  recordNumber = NULL,
  lastInterpreted = NULL,
  continent = NULL,
  geometry = NULL,
  geom_big = "asis",
  geom_size = 40,
  geom_n = 10,
  recordedBy = NULL,
  recordedByID = NULL,
  identifiedByID = NULL,
  basisOfRecord = NULL,
  datasetKey = NULL,
  eventDate = NULL,
  catalogNumber = NULL,
  year = NULL,
  month = NULL,
  decimalLatitude = NULL,
  decimalLongitude = NULL,
  elevation = NULL,
  depth = NULL,
  institutionCode = NULL,
  collectionCode = NULL,
  hasGeospatialIssue = NULL,
  issue = NULL,
  search = NULL,
  mediaType = NULL,
  subgenusKey = NULL,
  repatriated = NULL,
  phylumKey = NULL,
  kingdomKey = NULL,
  classKey = NULL,
  orderKey = NULL,
  familyKey = NULL,
  genusKey = NULL,
  establishmentMeans = NULL,
  protocol = NULL,
  license = NULL,
  organismId = NULL,
  publishingOrg = NULL,
  stateProvince = NULL,
  waterBody = NULL,
  locality = NULL,
  limit = 500,
  start = 0,
  fields = "all",
  return = NULL,
  facet = NULL,
  facetMincount = NULL,
  facetMultiselect = NULL,
  skip_validate = TRUE,
  curlopts = list(),
  ...
)
```
:::

------------------------------------------------------------------------

## 3.1 CZ mammals' GBIF data download

Get occurrence records of mammals from Czech Republic.

```{r}
#| echo: true
#| eval: true

occ_search(taxonKey=taxon_key,
           country='CZ') 
```

[By default it will only return the first 500 records]{.font-aside}

------------------------------------------------------------------------

## 3.1 CZ mammals' GBIF data download

To get **all** the records we need to specify a larger limit. Since we have over 8,000 records, we'll choose 9,000 as the limit.

```{r}
#| echo: true
#| eval: true
 

occ_search(taxonKey=taxon_key,
           country='CZ',
            limit=9000) 
```

------------------------------------------------------------------------

## 3.1 CZ mammals' GBIF data download

Finally, we store the result in the object `mammalsCZ`.

```{r}
#| echo: true
#| eval: true
mammalsCZ <- occ_search(
  taxonKey = taxon_key, # Key 359 created previously
  country = country_code, # CZ, ISO code of Czechia
  limit = 9000, # Max number of records to download
  hasGeospatialIssue = F # Only records without spatial issues
)

mammalsCZ <- mammalsCZ$data # The output of occ_search is a list with a data object inside. Here we pull the data out of the list.
```

------------------------------------------------------------------------

## 4 Data exploration

Mammals occurrence records from the Czech Republic

```{r}
#| echo: true
#| eval: true
glimpse(mammalsCZ)
```

[Check the data output. How many rows and columns does it have?]{.font-aside}

------------------------------------------------------------------------

## 4 Data exploration

Mammals occurrence records from the Czech Republic

How many records do we have?

::: {.fragment}
```{r}
#| echo: true
#| eval: true

nrow(mammalsCZ)
```
:::

<br>

::: {.fragment}
How many species do we have?

```{r}
#| echo: true
#| eval: true

mammalsCZ %>%
  filter(taxonRank == "SPECIES") %>%
  distinct(scientificName) %>%
  nrow()
```

[`distinct()` is used to see unique values]{.font-aside}
:::

## 5 Data quality

Data are not 'good' or 'bad', the quality will depend on our goal.\
Some things we can check:

::: incremental
-   Base of the record (type of occurrence)
-   Species names (taxonomic harmonisation)
-   Spatial and temporal (accuracy / precision)
:::

::: {.fragment}
![](https://docs.ropensci.org/CoordinateCleaner/logo.png){height="100"} `CoordinateCleaner`: <https://github.com/ropensci/CoordinateCleaner>

Automated flagging of common spatial and temporal errors in data.
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

As an example of data cleaning procedures, we will check the following fields in our dataset:

::: incremental
-   `basisOfRecord`: we want preserved specimens or observations
-   `taxonRank`: we want records at species level.
-   `coordinateUncertaintyInMeters`: we want it to be smaller than 10km.
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

-   `basisOfRecord`: we want preserved specimens or observations

::: {.fragment}
```{r}
#| echo: true
#| eval: true
mammalsCZ %>% distinct(basisOfRecord)
```

[`distinct()` is used to see unique values]{.font-aside}
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

-   `basisOfRecord`: we want preserved specimens or observations

::: {.fragment}
```{r}
#| echo: true
#| eval: true
mammalsCZ %>%
  group_by(basisOfRecord) %>%
  count()
  
```

[`group_by()` is used to group values within a variable]{.font-aside}
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

-   `basisOfRecord`: we want preserved specimens or observations

```{r}
#| echo: true
#| eval: true
mammalsCZ <- mammalsCZ %>%
  filter(basisOfRecord == "PRESERVED_SPECIMEN" |
    basisOfRecord == "HUMAN_OBSERVATION")
```

::: {.fragment}
[Note the use of `|` (OR) to filter the data. Another alternative is `filter(basisOfRecord %in% c("PRESERVED_SPECIMEN","HUMAN_OBSERVATION"))`.]{.font-aside}
:::

<br>

::: {.fragment}
How many records do we have now?

```{r}
#| echo: true
#| eval: true
nrow(mammalsCZ)
```
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

-   `taxonRank`: we want records at species level

::: {.fragment}
```{r}
#| echo: true
#| eval: true
mammalsCZ %>% distinct(taxonRank)
```
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

-   `taxonRank`: we want records at species level

```{r}
#| echo: true
#| eval: true
mammalsCZ <- mammalsCZ %>% 
  filter(taxonRank == 'SPECIES')
```

<br>

::: {.fragment}

How many records do we have now?

```{r}
#| echo: true
#| eval: true
nrow(mammalsCZ)
```
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

-   `coordinateUncertaintyInMeters`: we want them to be smaller than 10km

::: {.fragment}
```{r}
#| echo: true
#| eval: true
mammalsCZ %>%
  filter(coordinateUncertaintyInMeters >= 10000) %>%
  select(scientificName, 
         coordinateUncertaintyInMeters, 
         stateProvince)
  
```
:::

------------------------------------------------------------------------

## 5.1 Basic data filtering

-   `coordinateUncertaintyInMeters`: we want them to be smaller than 10km

```{r}
#| echo: true
#| eval: true
mammalsCZ <- mammalsCZ %>% 
  filter(coordinateUncertaintyInMeters < 10000) # keeping this
```

<br>

::: {.fragment}
How many records do we have now?

```{r}
#| echo: true
#| eval: true
nrow(mammalsCZ)
```
:::

------------------------------------------------------------------------

## 6 Basic maps

How are the records distributed?

::: {.fragment}
We'll get to this next week :)

```{r}
#| echo: false

mammalsCZ_sf <- mammalsCZ %>%
  filter(!is.na(decimalLongitude) &
    !is.na(decimalLatitude)) %>%
  st_as_sf(coords = c(
    "decimalLongitude",
    "decimalLatitude"
  )) %>%
  st_set_crs(proj_crs)

ggplot() +
  geom_sf(data = base_map, fill = "white") +
  geom_sf(
    data = sf::st_intersection(mammalsCZ_sf, base_map),
    aes(col = order)
  ) +
  theme_bw()
```
:::

## 6 Basic maps

And finally, a simple trick to produce separate maps per order.

```{r}
#| echo: false

ggplot() +
  geom_sf(data = base_map, fill = "white") +
  geom_sf(
    data = sf::st_intersection(mammalsCZ_sf, base_map),
    aes(col = order)
  ) +
  theme_bw() +
  # Added to the previous ggplot
  facet_wrap(~order) +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)
  )
```

# In summary

::: incremental
1.    Identify a data type and source\
2.    Check data-sharing agreements and licences\
3.    Download data and associated metadata\
4.    Check data quality (e.g., dates, spatial info, taxonomy) 
5.    Clean data for purpose\
:::

# Any doubts? {background-color="#488fb8"}
