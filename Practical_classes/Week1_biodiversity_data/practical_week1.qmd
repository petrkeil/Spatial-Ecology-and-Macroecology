---
title: 'Spatial Ecology and Macroecology'
subtitle: 'Practical - Week 1'
date: 2023-10-02
author: 'Florencia Grattarola, Friederike WÃ¶lke, Gabriel Ortega'
institute: '(Department of Spatial Sciences)'
format: 
  revealjs:
    self-contained: true
    logo: 'img/Logo_czu_cz_hr.png'
    auto-stretch: false
    code-copy: true
    code-tools: true
    enter-title-slide: false
    theme: [assets/monash.scss]
    controls: true
    width: 1280
    height: 720
    css: [assets/syntax-highlight.css, assets/custom.css, assets/pacman.css]
    highlight-style: github
    #preview-links: true
editor: visual
---

## What are we going to see today?

::: incremental
1.  Data types
2.  Data sources
3.  Open data
4.  Exercise 1: explore data sources
5.  Exercise 2: data download and cleaning in R
:::

# Data types {background-color="#5F9747"}

## 1. Data types

Data that can place a particular **taxa** in a particular **location** and **time** can take many forms.

------------------------------------------------------------------------

## 1. Data types

**Opportunistic incidence records**

::: columns
::: {.column width="60%"}
-   presence-only data from museum, herbarium collection or citizen-science initiatives
-   single species, spatio-temporally specific, unknown absences
:::

::: {.column width="40%"}
![](img/occurrence-records.png){fig-align="center" width="250"}
:::
:::

::: fragment
| PROS                                              | CONS                                                                   |
|------------------------------------|------------------------------------|
| huge amounts of data available, easily aggregated | often without details of effort/method, wide variation in data quality |
:::

------------------------------------------------------------------------

## 1. Data types

**Presence-absence data**

::: columns
::: {.column width="60%"}
-   data from inventories, checklists, atlas, acoustic sensors, DNA sampling or camera-trap sruveys
-   multiple species, spatio-temporally specific, report searches that did not find the species (absences)
:::

::: {.column width="40%"}
![](img/sampling-events.png){fig-align="center" width="250"}
:::
:::

::: fragment
| PROS                                                   | CONS                                                             |
|------------------------------------|------------------------------------|
| absences are informative, area and effort are measured | less abundant (too time consuming), methods are species-specific |
:::

------------------------------------------------------------------------

## 1. Data types

**Repeated surveys**

::: columns
::: {.column width="60%"}
-   monitoring schemes, repeated atlas projects
-   multiple species, over time, spatially defined, use a standardized protocol
:::

::: {.column width="40%"}
![](img/atlas_2.png){fig-align="center" width="250"}
:::
:::

::: fragment
| PRO                                             | CONS                                                         |
|------------------------------------|------------------------------------|
| standardised protocols, multiple points in time | expensive: geographically restricted, usually temporally too |
:::

------------------------------------------------------------------------

## 1. Data types

**Range-maps**

::: columns
::: {.column width="60%"}
-   outlines of species distributions, IUCN ranges, field guides
-   single species, expert-drawn
:::

::: {.column width="40%"}
![](img/range-map.png){fig-align="center" width="250"}
:::
:::

::: fragment
| PROS                                                                                      | CONS                                     |
|------------------------------------|------------------------------------|
| rough estimates of the outer boundaries of areas within which species are likely to occur | large spatial and temporal uncertainties |
:::

------------------------------------------------------------------------

## 1. Data types

Data can also be defined as **how** they were collected.

------------------------------------------------------------------------

## 1. Data types

**Structured**

::: {layout-ncol="2"}
-   clear survey design (location, target) and standardised sampling protocol
-   site selection: preselected locations, sometimes stratified random
-   metadata: informs about the survey methods

![](img/structured.png)
:::

------------------------------------------------------------------------

## 1. Data types

**Semi-structured**

::: {layout-ncol="2"}
-   no survey design but *little* standardised sampling protocol\
-   site selection: free\
-   metadata: informs about the observation process and survey methods

![](img/semi-structured.png)
:::

------------------------------------------------------------------------

## 1. Data types

**Unstructured** (opportunistic)

::: {layout-ncol="2"}
-   no survey design and no standardised sampling protocol
-   site selection: free
-   metadata: almost non

![](img/unstructured.png)
:::

------------------------------------------------------------------------

## 1. Data types

Finally, data can also be defined as how they are **made available** for others.

------------------------------------------------------------------------

## 1. Data types

**Disaggregated**

::: {layout-ncol="3"}
-   precision is high, but completeness and representativeness are low.

![](img/occurrence-records.png)

![](img/sampling-events.png)
:::

------------------------------------------------------------------------

## 1. Data types

**Aggregated**

::: {layout-ncol="3"}
-   precision is low, but completeness and representativeness are high.

![](img/range-map.png)

![](img/checklists.png)
:::

::: fragment
::: aside
While **disaggregated** data can produce reliable results for a limited set of well-covered regions, **aggregated** data types can provide critical information for the extrapolation of biodiversity patterns into less well-sampled regions.
:::
:::

# 2. Data sources {background-color="#5F9747"}

------------------------------------------------------------------------

![](img/gbif-full-logo-green.png){.centre top="200" height="200"}

### [gbif.org](https://www.gbif.org)

**GBIF** is an international network and data infrastructure funded by the world's governments and aimed at providing anyone, anywhere, open access to data about all types of life on Earth.

![](https://github.com/ropensci/rgbif/raw/master/man/figures/logo.png){height="100"} `rgbif`: <https://github.com/ropensci/rgbif>

------------------------------------------------------------------------

![](img/obis-logo.png){.centre top="200" height="200"}

### [obis.org](https://obis.org)

**OBIS** is a global open-access data and information clearing-house on marine biodiversity for science, conservation and sustainable development.

![](https://github.com/iobis/robis/raw/master/man/figures/logo.png){height="100"} `robis`: <https://github.com/iobis/robis>

------------------------------------------------------------------------

![](img/logo-ebird-1200.png){.centre top="200" height="200"}

### [ebird.org](https://ebird.org/home)

**eBird**'s goal is to gather birdwatcher's knowledge and experience in the form of checklists of birds, archive it, and freely share it to power new data-driven approaches to science, conservation and education.

![](https://cornelllabofornithology.github.io/auk/logo.png){height="100"} `auk`: <https://cornelllabofornithology.github.io/auk/>

------------------------------------------------------------------------

![](img/logo-ebird-1200.png){.centre top="200" height="200"}

### [ebird.org](https://ebird.org/home)

**eBird**'s goal is to gather birdwatcher's knowledge and experience in the form of checklists of birds, archive it, and freely share it to power new data-driven approaches to science, conservation and education.

![](https://docs.ropensci.org/rebird/logo.png){height="100"}\
`rebird`: [https://github.com/ropensci/rebird](https://github.com/ropensci/rebird/)

------------------------------------------------------------------------

![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/INaturalist_text_logo.svg/1280px-INaturalist_text_logo.svg.png){.centre top="200" height="100"}

### [inaturalist.org](https://www.inaturalist.org)

**iNaturalist** is one of the world's most popular nature apps. It allows participants to contribute observations of any organism, or traces thereof, along with associated spatio-temporal metadata.

![](https://docs.ropensci.org/rebird/logo.png){height="100"} `rinat`: <https://github.com/ropensci/rinat>

------------------------------------------------------------------------

![](https://mol.org/static/img/logo.png){.centre top="200" height="100"}

### [mol.org](https://mol.org)

**Map of Life** endeavors to provide 'best-possible' species range information and species lists for any geographic area. The Map of Life assembles and integrates different sources of data describing species distributions worldwide.

------------------------------------------------------------------------

![](img/IUCN_Red_List.png){.centre top="200" height="200"}

### [iucnredlist.org](https://www.iucnredlist.org)

**IUCN**'s (International Union for Conservation of Nature) Red List of Threatened Species has evolved to become the world's most comprehensive information source on the global extinction risk status of animal, fungus and plant species.

![](https://docs.ropensci.org/rebird/logo.png){height="100"} `rredlist`: <https://github.com/ropensci/rredlist>

------------------------------------------------------------------------

![](img/IUCN_Red_List.png){.centre top="200" height="200"}

### [iucnredlist.org](https://www.iucnredlist.org)

**IUCN**'s (International Union for Conservation of Nature) Red List of Threatened Species has evolved to become the world's most comprehensive information source on the global extinction risk status of animal, fungus and plant species.

![](https://avatars.githubusercontent.com/u/29559340?s=200&v=4){height="100"} `redlistr`: <https://github.com/red-list-ecosystem/redlistr>

------------------------------------------------------------------------

![](https://bien.nceas.ucsb.edu/bien/wp-content/uploads/2021/01/FinalBIENLogoNoText_highres-768x303.png){.centre top="200" width="352"}

### [bien.nceas.ucsb.edu/bien/](https://bien.nceas.ucsb.edu/bien/)

**BIEN** is a network of ecologists, botanists, and computer scientists working together to document global patterns of plant diversity, function and distribution.

`rbien`: <https://github.com/bmaitner/RBIEN>

------------------------------------------------------------------------

![](https://sibbr.gov.br/img/logo.svg){.centre top="200" height="200"}

### [sibbr.gov.br](https://sibbr.gov.br/?lang=en_GB)

**SiBBr** (Brazilian Biodiversity Information System) is an online platform that integrates data and information about biodiversity and ecosystems from different sources, making them accessible for different uses.

![](https://avatars.githubusercontent.com/u/4728758?s=200&v=4){height="100"} **sibbr**: <https://github.com/sibbr>

------------------------------------------------------------------------

![](https://www.bto.org/sites/all/themes/egret/img/logo/bbs-logo-square.png){.centre top="200" height="200"}

### [bto.org/our-science/projects/breeding-bird-survey](https://www.bto.org/our-science/projects/breeding-bird-survey)

**BBS** (Breeding Bird Survey) involves thousands of volunteer birdwatchers carrying out standardised annual bird counts on randomly-located 1-km sites. It's part of the NBN Atlas.

------------------------------------------------------------------------

![](http://biotime.st-andrews.ac.uk/images/logo.png){.centre top="200" height="200"}

### [biotime.st-andrews.ac.uk](https://biotime.st-andrews.ac.uk)

BioTime is an open access database global database of assemblage time series for quantifying and understanding biodiversity change.

![](https://avatars.githubusercontent.com/u/29038235?s=200&v=4){width="80"} **BioTime Hub**: <https://github.com/bioTIMEHub>

------------------------------------------------------------------------

![](img/Natural_History_Museum_London.png){.centre top="200" width="395"}

### [nhm.ac.uk/our-science/our-work/biodiversity/predicts](https://www.nhm.ac.uk/our-science/our-work/biodiversity/predicts.html)

**PREDICTS** uses data on local biodiversity around the world to model how human activities affect biological communities. This biodiversity change is shown as the Biodiversity Intactness Index (BII).

# 3. Open Data {background-color="#5F9747"}

## 3. Open Data

**Open** means anyone can freely access, use, modify, and share for any purpose.

<br>

![](http://opendefinition.org/assets.okfn.org/images/ok_buttons/od_80x15_blue.png){.centre top="200" height="50"}

------------------------------------------------------------------------

## 3. Open Data: Data standards

**Darwin Core** is the internationally agreed data standard to facilitate the sharing of information about biological diversity.

### [dwc.tdwg.org](https://dwc.tdwg.org/terms/)

. . .

::: columns
::: {.column width="40%"}
![](img/tdwg-logo-home.png){.centre top="200" height="200"}
:::

::: {.column width="60%"}
`countryCode`: The standard code for the country in which the Location occurs. Recommended best practice is to use an ISO 3166-1-alpha-2 country code.\
`recordedBy`: A list (concatenated and separated) of names of people, groups, or organizations responsible for recording the original Occurrence.
:::
:::

------------------------------------------------------------------------

## 3. Open Data: Licensing

Open data are licensed under open licenses. Some examples:

. . .

::: columns
::: {.column width="50%"}
![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/cc-zero.png)\
[**CC0**: Public domain]{.font-small}

![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by.png)\
[**CC-BY**: Attribution]{.font-small}
:::

::: {.column width="50%"}
![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc.png)\
[**CC-BY-NC**: Attribution - Non Commercial]{.font-small}

![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png)\
[**CC-BY-SA**: Attribution - Share Alike]{.font-small}
:::
:::

------------------------------------------------------------------------

## 3. Open Data: Data sharing

Data that are **standardized** and have an **open licence** can be shared :)

![](img/data-sharing.png){.absolute bottom="50" left="100" width="544" height="418"}

## 3. Open Data: use


**Workflow**  

::: incremental
1.    Identify and download raw data and associated metadata  
2.    Check data-sharing agreements and licenses  
3.    Check data quality (e.g., dates, spatial info, taxonomy) and clean data  
:::

# [EXERCISE 1]{.story} [Explore different data sources\...]{style="float:right;text-align:right;"} {background-color="#5F9747"}

## Imagine you want to start a project:

Chose a taxon, chose **one** data source and try to get distribution data.

Then answer the following 3 questions:

-   What kind of **data types** does the source provide?

-   Which kind of **taxa** are covered by the database generally?

-   How **accessible** is the data? Can anyone download it? Restrictions?

-   What was your **experience**? What **issues** did you encounter while getting the data?

::: aside
Should take around **5 minutes** :)\
Afterwards we will discuss some of your examples. Please be prepared to share your experience.
:::

# [EXERCISE 2]{.story} [Mammal's of the Czech Republic]{style="float:right;text-align:right;"} {background-color="#5F9747"}

We will use the mammals of Czech Republic as an example dataset. We will access data through [**GBIF**](https://gbif.org) using tools available in R.

## Some preparation before starting to code

. . .

-   Create a new project for all your practical sessions (with a Scripts and Data folder inside).
-   Comment your code as much as possible, as if you were to explain it to others (that other could be you in 3 months!).
-   Keep your code short and easily readable in plain English.

[File]{.font-big} \> [New project]{.font-big} \> [New directory]{.font-big} or [Existing directory]{.font-big}

## Some preparation before starting to code

. . .

-   Install the package `tidyverse`.

. . .

```{r}
#| echo: true
#| eval: false
#| code-block-border-left: true
install.packages('tidyverse') # install
```

```{r}
#| echo: true
#| eval: true
library(tidyverse) # load
```

. . .

<br> We will be using many functions from this package, like `filter()`, `mutate()`, and later `read_csv()`.

------------------------------------------------------------------------

## Some preparation before starting to code

We will use **`rgbif`**.

. . .

First, we'll need to **install** the package.

```{r}
#| echo: true
#| eval: false
install.packages('rgbif')
```

. . .

To use it, we **load** the library and check it's working.

```{r}
#| echo: true
#| eval: true
library(rgbif)
packageVersion('rgbif')
```

## Some preparation before starting to code

. . .

We will need the GBIF backbone taxon ID (`taxonKey`) for the *Mammalia* class. For that we will use another package called **`taxize`**.

```{r}
#| echo: true
#| eval: false
install.packages('taxize')
```

```{r}
#| echo: true
#| eval: true
library(taxize)
packageVersion('taxize')
```

## Some preparation before starting to code

. . .

Finally, we will install and load `sf`, which is a super useful library for mapping and spatial data analyses.

```{r}
#| echo: true
#| eval: false
install.packages('sf')
```

```{r}
#| echo: true
#| eval: true
library(sf)
packageVersion('sf')
```

## Data download through R

-   Create some variables that will be used later.

```{r}
#| echo: true
#| eval: true
taxa <- "Mammalia"
country_code <- "CZ" # Two letters ISO code for Czechia
proj_crs <- 4326 # EPSG code for WGS84
```

## Data download through R

So, let's get the taxon ID for the *Mammalia* class

. . .

```{r}
#| echo: true
#| eval: true
taxon_key <- get_gbifid_(taxa) %>%
  bind_rows() %>% # Transform the result of get_gbifid into a dataframe
  filter(matchtype == "EXACT" & status == "ACCEPTED") %>% # Filter the dataframe by the columns "matchtype" and "status"
  pull(usagekey) # Pull the contents of the column "usagekey"
```

## Data download through R

-   Get a base map that you could use later for plotting or checking the dataset.

```{r warning=FALSE,message=FALSE,echo=TRUE}
base_map <- rnaturalearth::ne_countries(
  scale = 110,
  type = "countries",
  country = "czechia",
  returnclass = "sf"
)
```

------------------------------------------------------------------------

## Data download through R

. . .

![](https://github.com/allisonhorst/stats-illustrations/raw/main/rstats-artwork/dplyr_filter.jpg){.absolute bottom="50" left="100" width="682" height="377"}

------------------------------------------------------------------------

## Data download through R

And now we can use the function `occ_count()` to find out the **number of occurrence records** for the entire Czech Republic.

. . .

``` r
occ_count(
  taxonKey = NULL,
  georeferenced = NULL,
  basisOfRecord = NULL,
  datasetKey = NULL,
  date = NULL,
  typeStatus = NULL,
  country = NULL,
  year = NULL,
  from = 2000,
  to = 2012,
  type = "count",
  publishingCountry = "US",
  protocol = NULL,
  curlopts = list()
)
```

------------------------------------------------------------------------

## Data download through R

How many occurrence records are in GBIF for the entire **Czech Republic**?

. . .

```{r}
#| echo: true
#| eval: true
occ_count(country=country_code) # country code for Czech Republic (https://countrycode.org/)
```

. . .

<br> And how many records for the **mammals** of Czech Republic?

. . .

```{r}
#| echo: true
#| eval: true
occ_count(
  country = country_code,
  taxonKey = taxon_key
)
```

. . .

<br> We are ready to do a download. [Whoop!]{.font-big}\

------------------------------------------------------------------------

## Data download through R

To do this, we will use `occ_search()`.

. . .

``` r
occ_search(
  taxonKey = NULL,
  scientificName = NULL,
  country = NULL,
  publishingCountry = NULL,
  hasCoordinate = NULL,
  typeStatus = NULL,
  recordNumber = NULL,
  lastInterpreted = NULL,
  continent = NULL,
  geometry = NULL,
  geom_big = "asis",
  geom_size = 40,
  geom_n = 10,
  recordedBy = NULL,
  recordedByID = NULL,
  identifiedByID = NULL,
  basisOfRecord = NULL,
  datasetKey = NULL,
  eventDate = NULL,
  catalogNumber = NULL,
  year = NULL,
  month = NULL,
  decimalLatitude = NULL,
  decimalLongitude = NULL,
  elevation = NULL,
  depth = NULL,
  institutionCode = NULL,
  collectionCode = NULL,
  hasGeospatialIssue = NULL,
  issue = NULL,
  search = NULL,
  mediaType = NULL,
  subgenusKey = NULL,
  repatriated = NULL,
  phylumKey = NULL,
  kingdomKey = NULL,
  classKey = NULL,
  orderKey = NULL,
  familyKey = NULL,
  genusKey = NULL,
  establishmentMeans = NULL,
  protocol = NULL,
  license = NULL,
  organismId = NULL,
  publishingOrg = NULL,
  stateProvince = NULL,
  waterBody = NULL,
  locality = NULL,
  limit = 500,
  start = 0,
  fields = "all",
  return = NULL,
  facet = NULL,
  facetMincount = NULL,
  facetMultiselect = NULL,
  skip_validate = TRUE,
  curlopts = list(),
  ...
)
```

------------------------------------------------------------------------

## Data download through R

Get occurrences records of mammals from Czech Republic.

```{r}
#| echo: true
#| eval: true
occ_search(taxonKey=taxon_key,
           country='CZ') 
```

[Check the data output. What's the format? How many rows does it have?]{.font-aside}

------------------------------------------------------------------------

## Data download through R

Get **all** occurrences records of mammals from Czech Republic.

```{r}
#| echo: true
#| eval: false
occ_search(taxonKey=taxon_key,
           country='CZ',
            limit=6000) 
```

. . .

<br>

Finally, we store the result in the object `mammalsCZ`.

```{r}
#| echo: true
#| eval: true
mammalsCZ <- occ_search(
  taxonKey = taxon_key, # Key 359 created previously
  country = country_code, # CZ, ISO code of Czechia
  limit = 6000, # Max number of records to download
  hasGeospatialIssue = F # Only records without spatial issues
)

mammalsCZ <- mammalsCZ$data # The output of occ_search is a list with a data object inside. Here we pull the data out of the list.
```

------------------------------------------------------------------------

## Data download through R

Mammals occurrence records from the Czech Republic

```{r}
#| echo: true
#| eval: true
glimpse(mammalsCZ)
```

------------------------------------------------------------------------

## Data download through R

Mammals occurrence records from the Czech Republic

How many records do we have?

. . .

```{r}
#| echo: true
#| eval: true
nrow(mammalsCZ)
```

. . .

<br>

How many species do we have?

. . .

```{r}
#| echo: true
#| eval: true
mammalsCZ %>%
  filter(taxonRank == "SPECIES") %>%
  distinct(scientificName) %>%
  nrow()
```

. . .

[`distinct()` is used to see unique values]{.font-aside}

# Data quality {background-color="#5F9747"}

## Data quality

Data are not 'good' or 'bad', the quality will depend on our goal.\
Some things we can check:

::: incremental
-   Base of the record (type of occurrence)
-   Species names (taxonomic harmonisation)
-   Spatial and temporal (accuracy / precision)
:::

. . .

![](https://docs.ropensci.org/CoordinateCleaner/logo.png){height="100"} `CoordinateCleaner`: <https://github.com/ropensci/CoordinateCleaner>

Automated flagging of common spatial and temporal errors in data.

------------------------------------------------------------------------

## Data quality

As an example, we will check the following fields:

::: incremental
-   `basisOfRecord`: we want preserved specimens or observations
-   `taxonRank`: we want records at species level.
-   `coordinateUncertaintyInMeters`: we want them to be smaller than 10km.
:::

------------------------------------------------------------------------

## Data quality

-   `basisOfRecord`: we want preserved specimens or observations

. . .

```{r}
#| echo: true
#| eval: true
mammalsCZ %>% distinct(basisOfRecord)
```

. . .

[`distinct()` is used to see unique values]{.font-aside}

------------------------------------------------------------------------

## Data quality

-   `basisOfRecord`: we want preserved specimens or observations

. . .

```{r}
#| echo: true
#| eval: true
mammalsCZ %>%
  group_by(basisOfRecord) %>%
  count()
  
```

. . .

[`group_by()` is used to group values within a variable]{.font-aside}

------------------------------------------------------------------------

## Data quality

-   `basisOfRecord`: we want preserved specimens or observations

```{r}
#| echo: true
#| eval: true
mammalsCZ <- mammalsCZ %>%
  filter(basisOfRecord == "PRESERVED_SPECIMEN" |
    basisOfRecord == "HUMAN_OBSERVATION")
```

. . .

[Note the use of `|` (OR) to filter the data. Another alternative is `filter(basisOfRecord %in% c("PRESERVED_SPECIMEN","HUMAN_OBSERVATION"))`.]{.font-aside}

. . .

<br>

How many records do we have now?

```{r}
#| echo: true
#| eval: true
nrow(mammalsCZ)
```

------------------------------------------------------------------------

## Data quality

-   `taxonRank`: we want records at species level

. . .

```{r}
#| echo: true
#| eval: true
mammalsCZ %>% distinct(taxonRank)
```

------------------------------------------------------------------------

## Data quality

-   `taxonRank`: we want records at species level

```{r}
#| echo: true
#| eval: true
mammalsCZ <- mammalsCZ %>% 
  filter(taxonRank == 'SPECIES')
```

. . .

<br>

How many records do we have now?

```{r}
#| echo: true
#| eval: true
nrow(mammalsCZ)
```

------------------------------------------------------------------------

## Data quality

-   `coordinateUncertaintyInMeters`: we want them to be smaller than 10km

. . .

```{r}
#| echo: true
#| eval: true
mammalsCZ %>%
  filter(coordinateUncertaintyInMeters >= 10000) %>%
  select(scientificName, 
         coordinateUncertaintyInMeters, 
         stateProvince)
  
```

------------------------------------------------------------------------

## Data quality

-   `coordinateUncertaintyInMeters`: we want them to be smaller than 10km

```{r}
#| echo: true
#| eval: true
mammalsCZ <- mammalsCZ %>% 
  filter(coordinateUncertaintyInMeters < 10000) # keeping this
```

. . .

<br>

How many records do we have now?

```{r}
#| echo: true
#| eval: true
nrow(mammalsCZ)
```

------------------------------------------------------------------------

## How are the records distributed?

. . .

We'll get to this next week :)

```{r}
#| echo: false
#| eval: true
library(sf)

mammalsCZ_sf <- mammalsCZ %>%
  filter(!is.na(decimalLongitude) &
    !is.na(decimalLatitude)) %>%
  st_as_sf(coords = c(
    "decimalLongitude",
    "decimalLatitude"
  )) %>%
  st_set_crs(proj_crs)

ggplot() +
  geom_sf(data = base_map, fill = "white") +
  geom_sf(
    data = sf::st_intersection(mammalsCZ_sf, base_map),
    aes(col = order)
  ) +
  theme_bw()
```

## How are the records distributed?

And finally, a simple trick to produce separate maps per order.

```{r}
ggplot() +
  geom_sf(data = base_map, fill = "white") +
  geom_sf(
    data = sf::st_intersection(mammalsCZ_sf, base_map),
    aes(col = order)
  ) +
  theme_bw() +
  # Added to the previous ggplot
  facet_wrap(~order) +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)
  )
```

------------------------------------------------------------------------

![](https://github.com/allisonhorst/stats-illustrations/raw/main/other-stats-artwork/debugging.jpg){.r-stretch}

------------------------------------------------------------------------

# Any doubts? {background-color="#5F9747"}
