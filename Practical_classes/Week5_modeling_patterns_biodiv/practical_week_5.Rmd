---
title: "Practical Class 5: Modeling patterns of biodiversity (markdown version)"
author: "Fran√ßois Leroy"
output: 
  html_document:
    toc: true
    toc_float: true
---

**Content of the practical work of today:**

The point of this class is to put you in the situation where you have to download, explore and exploit a large biodiversity dataset.
It is made to show you the steps that you are likely to follow when you are working with macroecological datasets.
We will work with one of the most famous and qualitative dataset in ecology: the North American Breeding Bird Survey (BBS).

The steps are as follow:

1.  Download the data and set up your R environment
2.  Explore the data through metadata
3.  Map the spatial extent of your dataset
4.  Assess and map the avian species richness for the year 2019
5.  Fit a linear model to predict species richness using a set of predictors

Finally, the last part of the workshop will be for you to use the tools we used during the class to work on two other metrics of biodiversity: the Shannon index (*i.e.* diversity) and the Pielou index (*i.e.* evenness).

# Download the North American BBS

[The North American BBS](https://www.pwrc.usgs.gov/bbs/) is an open source dataset that you can dowload directly [here](https://www.sciencebase.gov/catalog/item/52b1dfa8e4b0d9b325230cd9).
In `Child Items`, click `2022 Release - North American Breeding Bird Survey Dataset (1966-2021)` and under `Attached Files`, click on `download all`.
The download should start few seconds after.
Save the `.zip` archive into a `data` folder that you created in your working directory.

Now, unzip and erase the `2022Release_Nor.zip`.
Then, unzip all the `.zip` archives left.

# Explore the metadata

[Metadata](https://en.wikipedia.org/wiki/Metadata#:~:text=Metadata%20is%20%22data%20that%20provides,used%20for%20discovery%20and%20identification.) are information about the dataset you are using, but not the data itself.
When dealing with a large dataset, it often comes with a metadata file showing you the structure of the data.
Here, we have an `.xml` file: `North American Breeding Bird Survey Dataset (1966-2021).xml`.
To simply visualize it, drag and drop this file into your browser (firefox, google...).
Explore the structure of this file.
Keep this tab open as you will have to come back to it throughout this practical work.

# Map the BBS

Let's visualize the spatial coverage of the dataset.
Information about the roads can be found in the `road.csv` file.
First, explore the metadata file that you previously opened in your browser and find the information about the `road.csv` file.

-   Now, let's load the file:

```{r}
rm(list = ls()) ## Clear the environment when running the script
routes <- read.csv(file = "data/routes.csv")
head(routes)
```

-   In order to map the data contained into this file, we need to convert it into a shapefile:

```{r, warning=F, message=F}
## Create your own CRS for North America
crs_NA <- "+proj=laea +lon_0=-68.91 +lat_0=1.28 +datum=WGS84 +units=m +no_defs"

## Transform the dataframe into an sf object
library(sf)
routes_shp <- st_as_sf(routes, 
                       coords = c("Longitude", "Latitude"), ## specify the columns containing the longitude and latitude
                       crs = 4326) ## specify the CRS of the data 

## Set the crs to the one created above
routes_shp <- routes_shp %>% st_transform(crs = crs_NA)
head(routes_shp)
```

You can see that the colmuns `Latitude` and `Longitude` have been replaced by a single column `geometry` (which contains the shapefile data)

-   Now let's map it:

```{r, warning=F, message=F}
#################
# install.packages("rnaturalearthdata")
library(ggplot2)
library(dplyr)
library(rnaturalearth)
################

## You need to load the background map from the rnaturalearth package
countries_shp <- 
  ne_countries(scale = "medium", returnclass = "sf") %>% 
  filter(continent == "North America") %>% 
  st_transform(crs = crs_NA)

## Map it
ggplot()+
  geom_sf(data = countries_shp)+
  geom_sf(data = routes_shp, size = .5, color = "blue")+
  theme_bw()
```

# Compute map and model species richness

Species richness represents the total number of species at one location.
It is one of the most commonly used metric of biodiversity as it is really straight forward to assess.
Data about the species can be found in folder `50-StopData/1997ToPresent_SurveyWide/`.
They are spread on 10 excel spreadsheets (*do not forget to unzip them !!*).
In order to not repeat 10 times the loading process, we will automate it:

```{r, warning=FALSE, message=F}
library(readr)
## Get the file names
file_list <- list.files("data/50-StopData/1997ToPresent_SurveyWide/",
                        full.names = T)
## Create the dataframe that will contain the data
species <- data.frame()

## Loop over each file
for(i in 1:length(file_list)){
  
  ## Load the file and temporary store it
  d <- read_csv(file_list[i])
  
  ## Bind to the species dataframe
  species <- rbind(species, d)
  
  ## Remove the temporary data
  rm(d)
}
```

```{r, echo=F}
kableExtra::kable(head(species)) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::scroll_box(width = "100%", height = "200px")
```

<br>

**In the .xml file: find what does mean the `RouteDataID` and `AOU` columns refer to.**

## Compute

We are going to compute and display the avian species richness of each road for the year 2019

```{r}
## First let's filter the species datafram for the year 2019
### Here I provide 2 ways of doing it: either base R or tidyverse
sp2019 <- species[species$Year == 2019,]
sp2019 <- species %>% filter(Year == 2019)
###

### As it is written in the metadata. The species are given in the column AOU. 
## Thus, for each value of RouteDataID, we are going to assess the number of AOU
## Note that the AOU appears only if the species has been observed once in the 50 points
sr2019 <- sp2019 %>% 
  group_by(RouteDataID) %>% 
  summarize(sr_2019 = length(unique(AOU)),   ## Compute species richness
            CountryNum = unique(CountryNum), ## Keep the route info
            StateNum = unique(StateNum),     ## Keep the route info
            Route = unique(Route))           ## Keep the route info
head(sr2019)
```

## Map

In order to map the species richness, we need to add it to the object `routes_shp`

```{r}
## The class() of the coulmns StateNum and Route must be the same between the 2 datasets:
sr2019 <- mutate(sr2019, StateNum = as.numeric(StateNum),
                 Route = as.numeric(Route))
## Merge the 2 datasets using left join
routes_shp <- left_join(routes_shp, sr2019, 
                        by = c("CountryNum", "StateNum", "Route"))
```

**Now that you have computed the species richness, try to map it by adding it to the map we made at the beginning of the class**

```{r, echo=FALSE}
## Map
ggplot()+
  geom_sf(data = countries_shp)+
  geom_sf(data = na.omit(routes_shp), aes(color = sr_2019), size = 0.5)+
  scale_color_viridis_c()+
  ggtitle("Avian species richness of each BBS road for year 2019")+
  theme_bw()+
  theme(plot.title = element_text(hjust = .5))
  
```

## Model species richness using linear regressions

Linear regression is the most iconic machine learning method.
The main assumption is that there is a linear relationship between the variable you want to predict (*a.k.a.* the target, the predicted variable, the output) and a set of predictors (*a.k.a.* covariates, features).

The relationship has a form of a linear function:

$$y = \beta _1x_1 + \beta _2x_2 \ldots \beta _nx_n + \beta _0$$

With $n$ the number of covariates.
Thus, $y$ can be represented in an (n+1)-dimensional space (called an hyperspace when $n+1 > 3$).
The goal of fitting a linear regression (but also of most of the machine learning algorithms) is to find the hyperplane which fits the most to $y$ (*i.e.* which explains most of the variance).
In machine learning, you do so by minimizing a *loss function*.
The loss function for a linear regression is called the **Residual Sum of Square** (*i.e. RSS*).

$$RSS = \sum _{i = 1}^n (y_i - \hat y_i)^2$$

Here, we will use weather data as covariates ($x_1\ldots x_n$) in order to predict the species richness for year 2019 ($y$).
Weather data is stored in the `weather.csv` file.

```{r, message=F, warning=F}
weather <- read_csv("data/weather.csv")
```

```{r, echo=F}
kableExtra::kable(head(weather)) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::scroll_box(width = "100%", height = "200px")
```

<br>

**Have a look at the definitions of the columns in the metadata file and try to assess which covariates would be worth to use in our model.**

We will use the following covariates:

-   Month
-   Temperature
-   Wind condition
-   Time of the day
-   Sky conditions

However, as you can see, the temperature, wind condition and time of the day need processing before fitting the model.

```{r, message=F, warning=F}
## First we need to convert temperature and time of the day to numeric
weather <- mutate(weather,
                  StartTemp = as.numeric(StartTemp),
                  EndTemp = as.numeric(EndTemp),
                  StartTime = as.numeric(StartTime),
                  EndTime = as.numeric(EndTime))

## We also need to homogenize the temperature to degree Celsius 
weather <- mutate(weather,
                  StartTemp = case_when(
                   TempScale == "F" ~ ((StartTemp - 32) * 5/9),
                   TRUE ~ StartTemp
                 ),
                 EndTemp = case_when(
                   TempScale == "F" ~ ((EndTemp - 32) * 5/9),
                   TRUE ~ EndTemp
                 ))

## Now, let's compute the average temperature for the road #####
weather$avgTemp <- round(rowMeans(weather[,c("StartTemp","EndTemp")], na.rm = T),
                         2)


```

The wind condition is an ordinal variable.
Each increasing level indicates a stronger wind level.
Thus, we can take the average number between the start and end of the road.
However, the number 9 indicates a lack of data.
Thus, we can replace 9 by `NA` as follow:

```{r}
weather$StartWind[weather$StartWind == 9] <- NA
weather$EndWind[weather$EndWind == 9] <- NA
```

**Now that the weather columns are prepared, compute the average number for the wind condition. Watch out: we do not want decimals!!**

```{r, echo=F}
weather$avgWind <- round(rowMeans(weather[,c("StartWind","EndWind")], na.rm = T))
```

The last covariate: the time of the day.
We are going to convert it into decimal hours.

```{r, warning=F, message=F}
library(lubridate) ## the best package to work with date/time formats in R

## First we need to modify how the hour is given: we will add ":" between hour:minutes 
weather$StartTime <- gsub('^([0-9]{1,2})([0-9]{2})$', '\\1:\\2' ,weather$StartTime)
weather$EndTime <- gsub('^([0-9]{1,2})([0-9]{2})$', '\\1:\\2' ,weather$EndTime)

## And convert it to a date format (almost always needed to work with date/time data)
weather$StartTime <- hm(weather$StartTime)
weather$EndTime <- hm(weather$EndTime)
```

```{r}
# Now you can check the class of the columns
class(weather$EndTime)
```

```{r}
## We can now convert it to decimal hours
weather$StartTime <- round(hour(weather$StartTime) + (minute(weather$StartTime)/60),
                           2)
weather$EndTime <- round(hour(weather$EndTime) + (minute(weather$EndTime)/60),
                           2)
```

**Now that you have `StartTime` and `EndTime` in decimal hours: create a new column `avgTime` which contains the mean hour of the day at which the census has been made (with 2 decimals).**

```{r, echo=FALSE}
weather$avgTime <- round(rowMeans(weather[,c("StartTime","EndTime")], na.rm = T), 2)
```

Concerning the `Sky` covariate, it is a cotegorical variable, and we can't average it.
Thus, we will use the `StartSky` covariate.
Here it is: we have the 5 covariates that we will use to model species richness.

```{r}
## Frst we can filter the weather data to only keep the info for 2019
weather <- weather[weather$Year == 2019,]

## You can see that now you have as many rows in weather than in sr2019
## We need to join the species richness to the weather data using the road/census ID
lm_data <- left_join(sr2019, weather, by = "RouteDataID") %>% 
  select(sr_2019, avgTemp, avgTime, avgWind, StartSky, Month) ## and keep only the covariates and target

## We can look at the classes of the data
sapply(lm_data, class)
```

You can see that all the columns are into an integer or numeric format.
This is problematic for the 3 covariates which are qualitative: namely `avgWind` (qualitative ordinal), `Month` (qualitative nominal) and `StartSky` (qualitative nominal).
Let's modify them:

```{r}
lm_data$StartSky <- factor(lm_data$StartSky)
lm_data$Month <- factor(lm_data$Month)
lm_data$avgWind <- factor(lm_data$avgWind, order = T)

## We can look at the classes of the data
str(lm_data)
```

We can now learn the model:

```{r}
lm_model <- lm(sr_2019 ~ ., data = lm_data) ## modeling sr_2019 as a function of all the other variables

summary(lm_model)
```

**Now, let's interpret the output of the model**

# Exercice: modeling Shannon index and evenness

The goal of this exercise will be to fit a linear model to an other index of diversity: the Shannon index $H$.
This index takes into account both the species richness (that we worked on just before) and the evenness (*i.e.* relative abundance between the species).
It is defined as follow:

$$H = -\sum_i^R p_i\ln p_i$$

With $R$ the total number of species and $p_i$ the proportion of individuals.
For each species$_i$ with $n_i$ individuals, $p_i = \frac{n_i}{N}$ (with $N$ the total number of individuals)

We are going to compute the Shannon index for the year 2019.
For this, we will use the function `diversity()` from the `vegan` package.

First, let's format the data:

```{r}
library(tidyr)
library(tibble)
## Compute the total abundance for each road and each species
sp2019$abundance <- rowSums(sp2019[,8:57])

## The diversity function needs a dataset formated as: roads x species
abundance2019 <-
  sp2019 %>% 
  select(RouteDataID, AOU, abundance) %>% 
  pivot_wider(names_from = "AOU",
              values_from = "abundance",
              values_fill = 0) %>% 
  column_to_rownames(var = "RouteDataID")

dim(abundance2019)
```

You can see that we have 3239 roads and 635 species.

## Now it is up to you

-   **Task 1:** Compute the shannon index using the `diversity()` function. You should obtain a named vector which looks like this (using `head()`)

```{r, message=F, warning=F, echo=FALSE}
library(vegan)
## Compute the Shannon index
h.2019 <- diversity(abundance2019, index = "shannon")
head(h.2019)
```

-   **Task 2:** using the `left_join()` function, try to merge the computed shannon index to `sr2019` dataframe then to the `routes_shp` dataframe. *Hint:* you can use the `rownames_to_column()` on the shannon vector.

```{r, echo=F}
## Create a dataframe from the Shannon index vector
shannon.df <- as.data.frame(h.2019) %>% rownames_to_column("RouteDataID") %>% mutate(RouteDataID = as.numeric(RouteDataID))

## Merge with the sr2019 dataframe
sr2019 <- 
left_join(sr2019, 
          shannon.df,
          by = "RouteDataID")

## Merge the sr2019 with the routes_shp
routes_shp <-
  left_join(routes_shp, 
            sr2019 %>% select(h.2019, CountryNum, StateNum, Route), 
            by = c("CountryNum", "StateNum", "Route"))

```

-   **Task 3:** Map it! You should obtain something like this. You can also compare this map to the species richness map

```{r, echo=F}
## Map
ggplot()+
  geom_sf(data = countries_shp)+
  geom_sf(data = na.omit(routes_shp), aes(color = h.2019), size = .5)+
  scale_color_viridis_c()+
  ggtitle("Shannon index of each BBS road for year 2019")+
  theme_bw()+
  theme(plot.title = element_text(hjust = .5))
```

-   **Task 4:** use the `left_join()` function to merge the Shannon index to the `weather` dataframe and create the data that you can use for a linear regression

```{r, echo=F}
## Join to the weather data
lm_data_shannon <- left_join(weather, shannon.df,
                             by = "RouteDataID")
## Select to columns of interest
lm_data_shannon <- 
  lm_data_shannon %>% select(h.2019, avgTemp, avgTime, avgWind, StartSky, Month)

### Don't forget to change the class of the qualitative variables !!!!#####
lm_data_shannon$StartSky <- factor(lm_data_shannon$StartSky)
lm_data_shannon$Month <- factor(lm_data_shannon$Month)
lm_data_shannon$avgWind <- factor(lm_data_shannon$avgWind, order = T)
#####

str(lm_data_shannon)
```

-   **Task 5:** fit the linear model to predict the Shannon index and use the `summary()` function

```{r,echo=F}
## Fit the model
lm_model_shannon <- lm(h.2019 ~ ., data = lm_data_shannon)

## Display it
summary(lm_model_shannon)
```

-   **Task 6:** interpret the output and compare it to the species richness model output. Is this different? Is it surprising?

**Bonus:** as said above, Shannon index is a summary of species richness and relative abundances.
The latter can also be called **evenness**.
Several ways to compute the evenness exist (*e.g.* gini index, Pielou index...).
Here we will use the Pielou index $J$, which formal definition is:

$$J = \frac{H}{log(R)}$$

Using the vegan package, you can compute it from the Shannon index `H` that you created just before as follow `J <- H/specnumber(abundance2019)`

Now, repeat the same task as above for the evenness index.
Especially, map it and compare it to species richness and Shannon index.

```{r, echo = F}
#" Compute evenness
J <- h.2019/specnumber(abundance2019)

###########
## Create a dataframe from the evenness vector
pielou.df <- as.data.frame(J) %>% rownames_to_column("RouteDataID") %>% mutate(RouteDataID = as.numeric(RouteDataID))

## Merge with the sr2019 dataframe
sr2019 <- 
left_join(sr2019, 
          pielou.df,
          by = "RouteDataID")

## Merge the sr2019 with the routes_shp
routes_shp <-
  left_join(routes_shp, 
            sr2019 %>% select(J, CountryNum, StateNum, Route), 
            by = c("CountryNum", "StateNum", "Route"))
###########
## Map
ggplot()+
  geom_sf(data = countries_shp)+
  geom_sf(data = na.omit(routes_shp), aes(color = J), size = .5)+
  scale_color_viridis_c(limits = c(min(J), .2))+
  ggtitle("Pielou index of each BBS road for year 2019")+
  theme_bw()+
  theme(plot.title = element_text(hjust = .5))

```
