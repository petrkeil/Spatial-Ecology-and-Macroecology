---
title: "Practical Class 5: Modeling patterns of biodiversity"
author: "Fran√ßois Leroy"
format: 
  html:
    toc: true
editor: visual
---

# What we will do today

# Download the North American BBS

[The North American BBS](https://www.pwrc.usgs.gov/bbs/) is an open source dataset that you can dowload directly [here](https://www.sciencebase.gov/catalog/item/52b1dfa8e4b0d9b325230cd9). In `Child Items`, click `2022 Release - North American Breeding Bird Survey Dataset (1966-2021)` and under `Attached Files`, click on `download all`. The download should start few seconds after. Save the `.zip` archive into a `data` folder that you created in your working directory.

Now, unzip and erase the `2022Release_Nor.zip`. Then, unzip all the `.zip` archives left.

# Explore the metadata

[Metadata](https://en.wikipedia.org/wiki/Metadata#:~:text=Metadata%20is%20%22data%20that%20provides,used%20for%20discovery%20and%20identification.) are information about the dataset you are using, but not the data itself. When dealing with a large dataset, it often comes with a metadata file showing you the structure of the data. Here, we have an `.xml` file: `North American Breeding Bird Survey Dataset (1966-2021).xml`. To simply visualize it, drag and drop this file into your browser (firefox, google...). Explore the structure of this file. Keep this tab open as you will have to come back to it throughout this practical work.

# Map the BBS

Let's visualize the spatial coverage of the dataset. Information about the roads can be found in the `road.csv` file. First, explore the metadata file that you previously opened in your browser and find the information about the `road.csv` file. 

* Now, let's load the file:
```{r}
rm(list = ls()) ## Clear the environment when running the script
routes <- read.csv(file = "data/routes.csv")
head(routes)
```

* In order to map the data contained into this file, we need to convert it into a shapefile:
```{r, warning=F, message=F}
## Create your own CRS for North America
crs_NA <- "+proj=laea +lon_0=-68.91 +lat_0=1.28 +datum=WGS84 +units=m +no_defs"

## Transform the dataframe into an sf object
library(sf)
routes_shp <- st_as_sf(routes, 
                       coords = c("Longitude", "Latitude"), ## specify the columns containing the longitude and latitude
                       crs = 4326) ## specify the CRS of the data 

## Set the crs to the one created above
routes_shp <- routes_shp %>% st_transform(crs = crs_NA)
head(routes_shp)
```

You can see that the colmuns `Latitude` and `Longitude` have been replaced by a single column `geometry` (which contains the shapefile data) 

* Now let's map it:
```{r, warning=F, message=F}
#################
library(ggplot2)
library(dplyr)
library(rnaturalearth)
################

## You need to load the background map from the rnaturalearth package
countries_shp <- 
  ne_countries(scale = "medium", returnclass = "sf") %>% 
  filter(continent == "North America") %>% 
  st_transform(crs = crs_NA)

## Map it
ggplot()+
  geom_sf(data = countries_shp)+
  geom_sf(data = routes_shp, size = .5, color = "blue")+
  theme_bw()
```

# Compute map and model species richness

Species richness represents the total number of species at one location. It is one of the most commonly used metric of biodiversity as it is really straight forward to assess it.
Data about the species can be found in folder `50-StopData/1997ToPresent_SurveyWide/`. They are spread on 10 excel spreadsheets (*do not forget to unzip them !!*).
In order to not repeat 10 times the loading process, we will automate it:

```{r, warning=FALSE, message=F}
library(readr)
## Get the file names
file_list <- list.files("data/50-StopData/1997ToPresent_SurveyWide/",
                        full.names = T)
## Create the dataframe that will contain the data
species <- data.frame()

## Loop over each file
for(i in 1:length(file_list)){
  
  ## Load the file and temporary store it
  d <- read_csv(file_list[i])
  
  ## Bind to the species dataframe
  species <- rbind(species, d)
  
  ## Remove the temporary data
  rm(d)
}
```

```{r, echo=F}
kableExtra::kable(head(species)) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::scroll_box(width = "100%", height = "200px")
```

<br>

**In the .xml file: find what does mean the `RouteDataID` and `AOU` columns refer to.**

## Compute

We are going to compute and display the avian species richness of each road for the year 2019

```{r}
## First let's filter the species datafram for the year 2019
### Here I provide 2 ways of doing it: either base R or tidyverse
sp2019 <- species[species$Year == 2019,]
sp2019 <- species %>% filter(Year == 2019)
###

### As it is written in the metadata. The species are given in the column AOU. 
## Thus, for each value of RouteDataID, we are going to assess the number of AOU
## Note that the AOU appears only if the species has been observed once in the 50 points
sr2019 <- sp2019 %>% 
  group_by(RouteDataID) %>% 
  summarize(sr_2019 = length(unique(AOU)),   ## Compute species richness
            CountryNum = unique(CountryNum), ## Keep the route info
            StateNum = unique(StateNum),     ## Keep the route info
            Route = unique(Route))           ## Keep the route info
head(sr2019)
```

## Map 

In order to map the species richness, we need to add it to the object `routes_shp`

```{r}
## The class() of the coulmns StateNum and Route must be the same between the 2 datasets:
sr2019 <- mutate(sr2019, StateNum = as.numeric(StateNum),
                 Route = as.numeric(Route))
## Merge the 2 datasets using left join
routes_shp <- left_join(routes_shp, sr2019, 
                        by = c("CountryNum", "StateNum", "Route"))
```

**Now that you have computed the species richness, try to map it by adding it to the map we made at the beginning of the class**

```{r, echo=FALSE}
## Map
ggplot()+
  geom_sf(data = countries_shp)+
  geom_sf(data = routes_shp, aes(color = sr_2019))+
  scale_color_viridis_c()+
  ggtitle("Avian species richness of each BBS road for year 2019")+
  theme_bw()+
  theme(plot.title = element_text(hjust = .5))
  
```
## Modeling species richness using linear regressions

Linear regression is the most iconic machine learning method. The main assumption is that there is a linear relationship between 
the variable you want to predict (*a.k.a.* the target, the predicted variable, the output) and a set of predictors (*a.k.a.* covariates, features).

The relationship has a form of a linear function:

$$y = \beta _1x_1 + \beta _2x_2 \ldots \beta _nx_n + \beta _0$$ 

With $n$ the number of covariates. Thus, $y$ can be represented in an (n+1)-dimensional space (called an hyperspace when $n+1 > 3$). 
The goal of fitting a linear regression (but also of most of the machine learning algorithms) 
is to find the hyperplane which fits the most to $y$ (*i.e.* which explains most of the variance). In machine learning, you do so by minimizing a *loss function*. 
The loss function for a linear regression is called the **Residual Sum of Square** (*i.e. RSS*). 

$$RSS = \sum _{i = 1}^n (y_i - \hat y_i)^2$$

Here, we will use weather data as covariates ($x_1\ldots x_n$) in order to predict the species richness for year 2019 ($y$).
Weather data is stored in the `weather.csv` file. 
```{r, message=F, warning=F}
weather <- read_csv("data/weather.csv")
```

```{r, echo=F}
kableExtra::kable(head(weather)) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::scroll_box(width = "100%", height = "200px")
```

<br>

**Have a look at the definitions of the columns in the metadata file and try to assess which covariates would be worth to use in our model.**

We will use the following covariates: 

* Month
* Temperature
* Wind condition
* Time of the day

However, as you can see, the temperature, wind condition and time of the day need processing before fitting the model.

```{r, message=F, warning=F}
## First we need to convert temperature and time of the day to numeric
weather <- mutate(weather,
                  StartTemp = as.numeric(StartTemp),
                  EndTemp = as.numeric(EndTemp),
                  StartTime = as.numeric(StartTime),
                  EndTime = as.numeric(EndTime))

## We also need to homogenize the temperature to degree Celsius 
weather <- mutate(weather,
                  StartTemp = case_when(
                   TempScale == "F" ~ ((StartTemp - 32) * 5/9),
                   TRUE ~ StartTemp
                 ),
                 EndTemp = case_when(
                   TempScale == "F" ~ ((EndTemp - 32) * 5/9),
                   TRUE ~ EndTemp
                 ))

## Now, let's compute the average temperature for the road #####
weather$avgTemp <- round(rowMeans(weather[,c("StartTemp","EndTemp")], na.rm = T),
                         2)


```

The wind condition is a semi-continuous variable. 
Each increasing level indicates a stronger wind level. 
Thus, we can take the average number between the start and end of the road. 
However, the number 9 indicates a lack of data. Thus, we can replace 9 by `NA` as follow:

```{r}
weather$StartWind[weather$StartWind == 9] <- NA
weather$EndWind[weather$EndWind == 9] <- NA
```

**Now that the weather columns are prepared, compute the average number for the wind condition. Watch out: we do not want decimals!!**

```{r, echo=F}
weather$avgWind <- round(rowMeans(weather[,c("StartWind","EndWind")], na.rm = T))
```

